{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "import torch\n",
    "\n",
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_folder_path = r'C://Users//rolan//Desktop//Wooden_things//train'\n",
    "train_csv_path = r'C://Users//rolan//Desktop//Wooden_things//train_csv.csv'\n",
    "\n",
    "test_folder_path = r'C://Users//rolan//Desktop//Wooden_things//test'\n",
    "test_csv_path = r'C://Users//rolan//Desktop//Wooden_things//test_csv.csv'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "save_model_path = r'Models'\n",
    "save_plot_path = r'Plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "\n",
    "image_transforms = transforms.Compose([transforms.Resize(size = image_size), transforms.ToTensor()]) # Noramlisation if needed #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "train_data = CustomDataSet(folder_path = train_folder_path, csv_path = train_csv_path, transforms = image_transforms)\n",
    "test_data = CustomDataSet(folder_path = test_folder_path, csv_path = test_csv_path, transforms = image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample batch\n",
    "plot_batch_samples(train_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from classifier_model import LinearWood\n",
    "\n",
    "# Move to GPU\n",
    "wt_model = LinearWood().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = wt_model.parameters(), lr=1e-3, weight_decay=0.00005, betas = (0.85, 0.99))\n",
    "#optimizer = torch.optim.SGD(params = wt_model.parameters(), lr=0.2, weight_decay=0.0001)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training\n",
    "\n",
    "def train(model, loss_function, optimizer, the_data_loader):\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "\n",
    "    #Itterate through the dataset\n",
    "    for idx, (sample_batch) in enumerate(the_data_loader):\n",
    "        image = sample_batch['image']\n",
    "        label = sample_batch['label']\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        prediction = model.forward(image)\n",
    "\n",
    "        loss = loss_function(prediction, label)\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        #initialise the optimiser\n",
    "        optimizer.step()\n",
    "        #reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f'The loss is:{loss.item()}')\n",
    "    return train_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_function, dataloader, dataset):\n",
    "    batchsize = len(dataloader)\n",
    "    dataset_length = len(dataset)\n",
    "    test_loss, total_correct_guesses = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sample_batch in dataloader: #sample_batch\n",
    "            input = sample_batch['image']\n",
    "            label = sample_batch['label']\n",
    "            input, label = input.to(device), label.to(device)\n",
    "\n",
    "            output = model.forward(input)\n",
    "            test_loss += loss_function(output, label)\n",
    "            total_correct_guesses += (output.argmax(1) == torch.argmax(label, dim=1)).type(torch.float).sum().item()\n",
    "\n",
    "    avr_loss = test_loss / batchsize\n",
    "    avr_loss = '{:f}'.format(avr_loss)\n",
    "    accuracy = total_correct_guesses / dataset_length\n",
    "\n",
    "    print(f'Model Accuracy: {accuracy*100}% \\n Average Loss {avr_loss}')\n",
    "\n",
    "    return avr_loss, accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime\n",
    "\n",
    "def train_loop(epochs):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    accuracy_list= []\n",
    "    current_time = str(datetime.now()).replace(' ', '').replace('.', '').replace(':', '')\n",
    "\n",
    "    for idx, i in enumerate(range(epochs)):\n",
    "        print(f'Epoch{i+1} \\n --------------------------------------')\n",
    "\n",
    "        #train the model\n",
    "        train_loss = train(model = wt_model, loss_function = loss, optimizer = optimizer, the_data_loader = train_loader)\n",
    "        test_loss, accuracy = test(model = wt_model, loss_function = loss, dataloader = test_loader, dataset = test_data)\n",
    "\n",
    "        '''plot the graphs as the model trains'''\n",
    "        #sort the data for the plots        \n",
    "        for i in train_loss:\n",
    "            train_loss_list.append(round(i, 3))\n",
    "        test_loss_list.append(round(float(test_loss), 3))\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        #close previous plots to free up memory\n",
    "        plt.close('all')\n",
    "        \n",
    "        #create and format the figure\n",
    "        loss_fig, (ax_train, ax_test, ax_acc) = plt.subplots(nrows=3, ncols=1)\n",
    "        loss_fig.set_size_inches(5, 5)\n",
    "        loss_fig.set_dpi(72)\n",
    "        plt.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "        #plot the data on the axes\n",
    "        ax_train.plot(list(range(len(train_loader)*(idx+1))), train_loss_list, color='#1f77b4')\n",
    "        ax_train.set_title('Training Loss/batch')\n",
    "        ax_train.set_xlabel('Batches')\n",
    "        ax_train.set_ylabel('Loss')\n",
    "        ax_train.grid(True)\n",
    "\n",
    "        ax_test.plot(list(range(idx+1)), test_loss_list, color='#ff7f0e')\n",
    "        ax_test.set_title('Test Loss/Epoch')\n",
    "        ax_test.set_xlabel('Epochs')\n",
    "        ax_test.set_ylabel('Loss')\n",
    "        ax_test.grid(True)\n",
    "\n",
    "        ax_acc.plot(list(range(idx+1)), accuracy_list, color='#2ca02c')\n",
    "        ax_acc.set_title('Model Accuracy')\n",
    "        ax_acc.set_xlabel('Epochs')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.grid(True)\n",
    "\n",
    "        #save the model\n",
    "        a = 0\n",
    "        if idx % 10 == 0:\n",
    "            a += 1\n",
    "            torch.save(obj = wt_model.state_dict(), f=f'{save_model_path}//Experiment_{a}_{current_time[:-12]}_{str(accuracy)[:2]}.pth')\n",
    "            print(f'Saved model as Experiment_{a}.pth')\n",
    "        print('Finished')\n",
    "\n",
    "        #plt.pause(0.1)\n",
    "        plt.show()\n",
    "\n",
    "        loss_fig.savefig(fname=f'{save_plot_path}//model_x_{current_time}.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(epochs = 81)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
