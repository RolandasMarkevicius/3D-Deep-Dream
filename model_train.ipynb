{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom DataSet Class\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, folder_path, csv_path, transforms = None):\n",
    "        #get all the necessary parameters for directories, labels and transforms\n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "        self.folder_path = folder_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        #get the length of the dataset\n",
    "        class_length = len(self.csv.iloc[:, 1])\n",
    "        return class_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #get the dataset item and label and set transforms\n",
    "        self.image_path_list = [os.path.join(self.folder_path, image_name) for image_name in self.csv.iloc[:, 0]]\n",
    "        self.one_hot_label = pd.get_dummies(self.csv.iloc[:, 1])\n",
    "        self.one_hot_label_list = self.one_hot_label.values.tolist()\n",
    "\n",
    "        self.image_path = self.image_path_list[idx]\n",
    "        self.image = Image.open(self.image_path)\n",
    "        self.label = torch.tensor(self.one_hot_label_list[idx]).float()\n",
    "\n",
    "        if self.transforms:\n",
    "            self.image = self.transforms(self.image)\n",
    "\n",
    "        sample = {'image': self.image, 'label': self.label}     \n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "import torch\n",
    "\n",
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_folder_path = r'C://Users//rolan//Desktop//Wooden_things//train'\n",
    "train_csv_path = r'C://Users//rolan//Desktop//Wooden_things//train_csv.csv'\n",
    "\n",
    "test_folder_path = r'C://Users//rolan//Desktop//Wooden_things//test'\n",
    "test_csv_path = r'C://Users//rolan//Desktop//Wooden_things//test_csv.csv'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "save_model_path = r'Models'\n",
    "save_plot_path = r'Plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "\n",
    "image_transforms = transforms.Compose([transforms.Resize(size = image_size), transforms.ToTensor()]) # Noramlisation if needed #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "train_data = CustomDataSet(folder_path = train_folder_path, csv_path = train_csv_path, transforms = image_transforms)\n",
    "test_data = CustomDataSet(folder_path = test_folder_path, csv_path = test_csv_path, transforms = image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise batch data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "def plot_batch_samples(data_loader, batch_size):\n",
    "\n",
    "    log = math.log(batch_size, 2)\n",
    "    rows = 2**math.ceil(log/2)\n",
    "    columns = 2**math.ceil(log/2)\n",
    "\n",
    "    fig = plt.figure(figsize = (3*columns, 3*rows), dpi = 72)\n",
    "\n",
    "    for idx, sample in zip(list(range(batch_size)), data_loader):\n",
    "        axis = fig.add_subplot(rows, columns, idx+1)\n",
    "        np_image = sample['image'].numpy()\n",
    "        np_image = np_image.transpose((1, 2, 0))\n",
    "        axis.axis('off')\n",
    "        axis.set_title(label = sample['label'])\n",
    "        axis.imshow(np_image)\n",
    "    plt.show()\n",
    "\n",
    "plot_batch_samples(train_data, batch_size = batch_size)\n",
    "\n",
    "#define as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWood(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=2, padding=0, dilation=1) #126\n",
    "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1)#62\n",
    "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=2, padding=0, dilation=1) #30\n",
    "    self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1)#14\n",
    "    self.conv3 = nn.Conv2d(in_channels=12, out_channels=36, kernel_size=3, stride=2, padding=0, dilation=1) #6\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "    self.linear_stack = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(1296, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(512, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),      \n",
    "        nn.Linear(64, 4),\n",
    "        nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    prediction = self.conv1(x)\n",
    "    prediction = self.relu(prediction)\n",
    "    prediction = self.dropout(prediction)\n",
    "\n",
    "    prediction = self.maxpool1(prediction)\n",
    "\n",
    "    prediction = self.conv2(prediction)\n",
    "    prediction = self.relu(prediction)\n",
    "    prediction = self.dropout(prediction)\n",
    "\n",
    "    prediction = self.maxpool2(prediction)\n",
    "\n",
    "    prediction = self.conv3(prediction)\n",
    "    prediction = self.relu(prediction)\n",
    "    prediction = self.dropout(prediction)\n",
    "\n",
    "    prediction = self.linear_stack(prediction)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Move to GPU\n",
    "wt_model = LinearWood().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = wt_model.parameters(), lr=1e-3, weight_decay=0.00005, betas = (0.85, 0.99))\n",
    "#optimizer = torch.optim.SGD(params = wt_model.parameters(), lr=0.2, weight_decay=0.0001)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training\n",
    "\n",
    "def train(model, loss_function, optimizer, the_data_loader):\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "\n",
    "    #Itterate through the dataset\n",
    "    for idx, (sample_batch) in enumerate(the_data_loader):\n",
    "        image = sample_batch['image']\n",
    "        label = sample_batch['label']\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        prediction = model.forward(image)\n",
    "\n",
    "        loss = loss_function(prediction, label)\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        #initialise the optimiser\n",
    "        optimizer.step()\n",
    "        #reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f'The loss is:{loss.item()}')\n",
    "    return train_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_function, dataloader, dataset):\n",
    "    batchsize = len(dataloader)\n",
    "    dataset_length = len(dataset)\n",
    "    test_loss, total_correct_guesses = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sample_batch in dataloader: #sample_batch\n",
    "            input = sample_batch['image']\n",
    "            label = sample_batch['label']\n",
    "            input, label = input.to(device), label.to(device)\n",
    "\n",
    "            output = model.forward(input)\n",
    "            test_loss += loss_function(output, label)\n",
    "            total_correct_guesses += (output.argmax(1) == torch.argmax(label, dim=1)).type(torch.float).sum().item()\n",
    "\n",
    "    avr_loss = test_loss / batchsize\n",
    "    avr_loss = '{:f}'.format(avr_loss)\n",
    "    accuracy = total_correct_guesses / dataset_length\n",
    "\n",
    "    print(f'Model Accuracy: {accuracy*100}% \\n Average Loss {avr_loss}')\n",
    "\n",
    "    return avr_loss, accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime\n",
    "\n",
    "def train_loop(epochs):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    accuracy_list= []\n",
    "    current_time = str(datetime.now()).replace(' ', '').replace('.', '').replace(':', '')\n",
    "\n",
    "    for idx, i in enumerate(range(epochs)):\n",
    "        print(f'Epoch{i+1} \\n --------------------------------------')\n",
    "\n",
    "        #train the model\n",
    "        train_loss = train(model = wt_model, loss_function = loss, optimizer = optimizer, the_data_loader = train_loader)\n",
    "        test_loss, accuracy = test(model = wt_model, loss_function = loss, dataloader = test_loader, dataset = test_data)\n",
    "\n",
    "        '''plot the graphs as the model trains'''\n",
    "        #sort the data for the plots        \n",
    "        for i in train_loss:\n",
    "            train_loss_list.append(round(i, 3))\n",
    "        test_loss_list.append(round(float(test_loss), 3))\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        #close previous plots to free up memory\n",
    "        plt.close('all')\n",
    "        \n",
    "        #create and format the figure\n",
    "        loss_fig, (ax_train, ax_test, ax_acc) = plt.subplots(nrows=3, ncols=1)\n",
    "        loss_fig.set_size_inches(5, 5)\n",
    "        loss_fig.set_dpi(72)\n",
    "        plt.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "        #plot the data on the axes\n",
    "        ax_train.plot(list(range(len(train_loader)*(idx+1))), train_loss_list, color='#1f77b4')\n",
    "        ax_train.set_title('Training Loss/batch')\n",
    "        ax_train.set_xlabel('Batches')\n",
    "        ax_train.set_ylabel('Loss')\n",
    "        ax_train.grid(True)\n",
    "\n",
    "        ax_test.plot(list(range(idx+1)), test_loss_list, color='#ff7f0e')\n",
    "        ax_test.set_title('Test Loss/Epoch')\n",
    "        ax_test.set_xlabel('Epochs')\n",
    "        ax_test.set_ylabel('Loss')\n",
    "        ax_test.grid(True)\n",
    "\n",
    "        ax_acc.plot(list(range(idx+1)), accuracy_list, color='#2ca02c')\n",
    "        ax_acc.set_title('Model Accuracy')\n",
    "        ax_acc.set_xlabel('Epochs')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.grid(True)\n",
    "\n",
    "        #save the model\n",
    "        a = 0\n",
    "        if idx % 10 == 0:\n",
    "            a += 1\n",
    "            torch.save(obj = wt_model.state_dict(), f=f'{save_model_path}//Experiment_{a}_{current_time[:-12]}_{str(accuracy)[:2]}.pth')\n",
    "            print(f'Saved model as Experiment_{a}.pth')\n",
    "        print('Finished')\n",
    "\n",
    "        #plt.pause(0.1)\n",
    "        plt.show()\n",
    "\n",
    "        loss_fig.savefig(fname=f'{save_plot_path}//model_x_{current_time}.pdf', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(epochs = 81)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
