{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "\n",
    "image_size = (325, 325)\n",
    "batch_size = 32\n",
    "\n",
    "train_folder_path = r'C://Users//rolan//Desktop//Wooden_things//train'\n",
    "train_csv_path = r'C://Users//rolan//Desktop//Wooden_things//train_csv.csv'\n",
    "\n",
    "test_folder_path = r'C://Users//rolan//Desktop//Wooden_things//test'\n",
    "test_csv_path = r'C://Users//rolan//Desktop//Wooden_things//test_csv.csv'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "save_model_path = r'Models'\n",
    "save_plot_path = r'Plots'\n",
    "\n",
    "# DataSet\n",
    "\n",
    "image_transforms = transforms.Compose([transforms.Resize(size = image_size), transforms.ToTensor()]) # Noramlisation if needed #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "train_data = CustomDataSet(folder_path = train_folder_path, csv_path = train_csv_path, transforms = image_transforms)\n",
    "test_data = CustomDataSet(folder_path = test_folder_path, csv_path = test_csv_path, transforms = image_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample batch\n",
    "#plot_batch_samples(data_loader=train_loader, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from model_architecture import LinearWood\n",
    "\n",
    "# Move to GPU\n",
    "wt_model = LinearWood().to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params = wt_model.parameters(), lr=0.001, weight_decay=0.001, betas = (0.85, 0.99))\n",
    "#optimizer = torch.optim.SGD(params = wt_model.parameters(), lr=0.25, weight_decay=0.01)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "\n",
    "def train(model, dataloader, loss_f, optim_f):\n",
    "  # set the model to train mode?\n",
    "  model.train()\n",
    "\n",
    "  # for plotting loss with matplotlib\n",
    "  loss_list = []\n",
    "\n",
    "  for idx, x in enumerate(dataloader):\n",
    "\n",
    "    # move inputs and labels to the GPU\n",
    "    x, y = x['image'].to(device), x['label'].to(device)\n",
    "\n",
    "    # forward pass\n",
    "    prediction = model.forward(x)\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = loss_f(prediction, y)\n",
    "\n",
    "    # calculate the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights with optimizer\n",
    "    optim_f.step()\n",
    "\n",
    "    # zero the gradients\n",
    "    optim_f.zero_grad()\n",
    "\n",
    "    #print the training loss\n",
    "    if idx % 10 == 0:\n",
    "      print(f'training loss = {loss.item()}')\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "  return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop\n",
    "\n",
    "def test(model, dataloader, loss_f, dataset):\n",
    "  # set the model to evaluate mode\n",
    "  model.eval()\n",
    "  loss_sum = 0\n",
    "  accuracy_sum = 0\n",
    "\n",
    "  #create loss and accuracy variables\n",
    "  with torch.no_grad():\n",
    "\n",
    "    # set a loop over the batches\n",
    "    for x in dataloader:\n",
    "\n",
    "      # move inputs and labels to the GPU #'image': self.image, 'label'\n",
    "      x, y = x['image'].to(device), x['label'].to(device)\n",
    "\n",
    "      # run the forwards pass\n",
    "      prediction = model.forward(x)\n",
    "\n",
    "      # calculate the loss\n",
    "      loss = loss_f(prediction, y)\n",
    "\n",
    "      # total loss over all the batches\n",
    "      loss_sum += loss\n",
    "\n",
    "      # toatl accuracy over all the batches\n",
    "      accuracy_sum += (prediction.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "  # average loss\n",
    "  avg_loss = loss_sum / len(dataloader)\n",
    "  avg_loss = '{:f}'.format(avg_loss)\n",
    "\n",
    "  #average accuracy\n",
    "  avg_accuracy = accuracy_sum / len(dataset)\n",
    "\n",
    "  # print the loss and accuracy\n",
    "  print(f'Epoch loss = {avg_loss} \\n Epoch accuracy = {avg_accuracy*100}%')\n",
    "\n",
    "  return avg_loss, avg_accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime\n",
    "\n",
    "def train_loop(epochs):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    accuracy_list= []\n",
    "    current_time = str(datetime.now()).replace(' ', '').replace('.', '').replace(':', '')\n",
    "\n",
    "    for idx, i in enumerate(range(epochs)):\n",
    "        print(f'Epoch{i+1} \\n --------------------------------------')\n",
    "\n",
    "        #train the model\n",
    "        train_loss = train(model = wt_model, loss_f=loss, optim_f=optimizer, dataloader=train_loader)\n",
    "        test_loss, accuracy = test(model = wt_model, loss_f = loss, dataloader = test_loader, dataset = test_data)\n",
    "\n",
    "        '''plot the graphs as the model trains'''\n",
    "        #sort the data for the plots        \n",
    "        for i in train_loss:\n",
    "            train_loss_list.append(round(i, 3))\n",
    "        test_loss_list.append(round(float(test_loss), 3))\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        #close previous plots to free up memory\n",
    "        plt.close('all')\n",
    "        \n",
    "        #create and format the figure\n",
    "        loss_fig, (ax_train, ax_test, ax_acc) = plt.subplots(nrows=3, ncols=1)\n",
    "        loss_fig.set_size_inches(5, 5)\n",
    "        loss_fig.set_dpi(72)\n",
    "        plt.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "        #plot the data on the axes\n",
    "        ax_train.plot(list(range(len(train_loader)*(idx+1))), train_loss_list, color='#1f77b4')\n",
    "        ax_train.set_title('Training Loss/batch')\n",
    "        ax_train.set_xlabel('Batches')\n",
    "        ax_train.set_ylabel('Loss')\n",
    "        ax_train.grid(True)\n",
    "\n",
    "        ax_test.plot(list(range(idx+1)), test_loss_list, color='#ff7f0e')\n",
    "        ax_test.set_title('Test Loss/Epoch')\n",
    "        ax_test.set_xlabel('Epochs')\n",
    "        ax_test.set_ylabel('Loss')\n",
    "        ax_test.grid(True)\n",
    "\n",
    "        ax_acc.plot(list(range(idx+1)), accuracy_list, color='#2ca02c')\n",
    "        ax_acc.set_title('Model Accuracy')\n",
    "        ax_acc.set_xlabel('Epochs')\n",
    "        ax_acc.set_ylabel('Accuracy')\n",
    "        ax_acc.grid(True)\n",
    "\n",
    "        #save the model\n",
    "        a = 0\n",
    "        if idx % 10 == 0:\n",
    "            a += 1\n",
    "            torch.save(obj = wt_model.state_dict(), f=f'{save_model_path}//Experiment_{a}_InstanceNorm2D_{current_time[:-12]}_{str(accuracy)[:2]}.pth')\n",
    "            print(f'Saved model as Experiment_{a}.pth')\n",
    "        print('Finished')\n",
    "\n",
    "        #plt.pause(0.1)\n",
    "        plt.show()\n",
    "\n",
    "        loss_fig.savefig(fname=f'{save_plot_path}//model_x_{current_time}.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 \n",
      " --------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 spatial element when training, got input size torch.Size([32, 512, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24416/2554036004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m81\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24416/43772090.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwt_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwt_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24416/4184295318.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, loss_f, optim_f)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rolan\\Desktop\\personal\\Projects\\DeepDream\\model_architecture.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchnorm6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_no_batch_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_instance_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\instancenorm.py\u001b[0m in \u001b[0;36m_apply_instance_norm\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply_instance_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         return F.instance_norm(\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             self.training or not self.track_running_stats, self.momentum, self.eps)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[0;32m   2492\u001b[0m         )\n\u001b[0;32m   2493\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2494\u001b[1;33m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2495\u001b[0m     return torch.instance_norm(\n\u001b[0;32m   2496\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_spatial_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2459\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2461\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 spatial element when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 spatial element when training, got input size torch.Size([32, 512, 1, 1])"
     ]
    }
   ],
   "source": [
    "train_loop(epochs = 81)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
